# benchmark4GPT
Our project provides 500 carefully designed questions that can be used to test and evaluate the performance of Generative Pretrained Transformer (GPT) models. The questions cover a variety of topics and domains and are designed to comprehensively examine the performance of GPT models Comprehension, creativity and logical reasoning skills.


# Refer
[ ] https://github.com/declare-lab/red-instruct
[ ] red team llm benchmark
  [X] https://evals.alignment.org/Evaluating_LMAs_Realistic_Tasks.pdf
  [X] https://www.alignmentforum.org/posts/iHmsJdxgMEWmAfNne/red-teaming-language-models-via-activation-engineering
  [ ] https://www.researchgate.net/publication/371684665_Explore_Establish_Exploit_Red_Teaming_Language_Models_from_Scratch
  [ ] https://aclanthology.org/2022.emnlp-main.225.pdf
  [ ] https://www.arxiv-sanity-lite.com/?rank=pid&pid=2310.12505
  [ ] https://llmsecurity.net/
  [ ] https://github.com/normster/llm_rules
  [ ] https://github.com/dmahan93/lm-evaluation-harness/tree/add-agieval/lm_eval
  [ ] Unlock better AI with RLHF and RLAIF 使用 RLHF 和 RLAIF 解锁更好的 AI
  [ ] 数据标注公司：
    [ ] https://labelbox.com/solutions/large-language-models/
