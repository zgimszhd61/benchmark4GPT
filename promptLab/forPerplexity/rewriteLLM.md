在100字以内，在下面这段对话里重新描述对话内容观点，合并同类项。并且把":"前面的单词作为索引，放到观点后面。

例如：
输入：
E:我觉得Gemini对现有生态不会有特别大的影响：1. 个人看法Gemini Ultra整体上没超过GPT4，Gemini Pro也没超过GPT3.5。Gemini相比GPT4-V最大的功能区别是增加了视频理解，但这个GPT肯定做了，只是还没发布出来。2. 模型e2e是有可能的。从LVM等最近的工作来看，基于GPT这种自回归的网络架构，不用任何文本的纯图像数据，也可以做到上下文学习（Context Learning），其中的例子也包括端到端的视频理解。视频本身就是图像序列，限于当前模型的context window长度，视频理解大概率是通过抽帧，转变成多张图像的序列，再喂给模型，所以文章里举的例子并不能说明Gemini没做端到端的视频理解，只是需要额外的一些工程处理。3. Gemini Ultra如果是dense模型的话，模型推理成本会很高（相比于GPT是MOE模型），可能没法支撑足够多的用户使用
A:Gemini 是多模态。如果价格和 GPT3.5 持平，text 上性能差一点，有 audio/image 能力（评测已经超过 whisper 了好像），那就是性价比最高的多模态了。这些对我们影响不到，因为我们没有用到多模态。
B:从目前公开的技术信息来看,Gemini是几种模态一起联合从头训练的，包括文本、图片、音频、视频等。这与目前通常的多模态做法不太一样.从学科能力测试数据看，目前大模型能力很可能顺序如下：GPT 4 略微强于Geminni ultra > Claude 2 > inflection-2 > GPT 3.5= Grok 1 >Llama2。从Gemini的效果来看,多种模态联合训练确实有用，但是它的用处主要在于：把文本抽象概念和物理实体形象的对应Grounding建立起来了，但是在大模型的世界知识和各种能力储备方面，经过大量视频强化过的Gemini甚至可能还比不过只用文本训练的GPT 4。本质上是大模型把从文本中学到的世界知识和逻辑能力，经过grounding绑定到实体外在形象后，在多模态场景下语言模型把丰富的世界知识迁移给了多模态模型.大量多模态训练数据新增的知识并不多.
C:可以用啊，我们试一试吧，推动产品来进步.

输出：
对于Gemini模型的影响观点不一致。E认为Gemini性能不超过之前的模型，视频理解可能已存在。Gemini在多模态性价比方面有潜力，但不会影响他们的应用[A]。Gemini的多模态训练与传统方法不同，但在世界知识方面可能不如GPT4[B]。Gemini有潜力推动产品进步。总体来看，Gemini的影响取决于性能、多模态能力和应用需求的不同[C]。

----

E:我觉得DDDD对现有生态不会有特别大的影响：1. 个人看法DDDD Ultra整体上没超过GPT4，DDDD Pro也没超过GPT3.5。DDDD相比GPT4-V最大的功能区别是增加了视频理解，但这个GPT肯定做了，只是还没发布出来。2. 模型e2e是有可能的。从LVM等最近的工作来看，基于GPT这种自回归的网络架构，不用任何文本的纯图像数据，也可以做到上下文学习（Context Learning），其中的例子也包括端到端的视频理解。视频本身就是图像序列，限于当前模型的context window长度，视频理解大概率是通过抽帧，转变成多张图像的序列，再喂给模型，所以文章里举的例子并不能说明Gemini没做端到端的视频理解，只是需要额外的一些工程处理。3. DDDD Ultra如果是dense模型的话，模型推理成本会很高（相比于GPT是MOE模型），可能没法支撑足够多的用户使用
A:Gemini 是多模态。如果价格和 GPT3.5 持平，text 上性能差一点，有 audio/image 能力（评测已经超过 whisper 了好像），那就是性价比最高的多模态了。这些对我们影响不到，因为我们没有用到多模态。
B:从目前公开的技术信息来看,Gemini是几种模态一起联合从头训练的，包括文本、图片、音频、视频等。这与目前通常的多模态做法不太一样.从学科能力测试数据看，目前大模型能力很可能顺序如下：GPT 4 略微强于DDDD ultra > Claude 2 > inflection-2 > GPT 3.5= Grok 1 >Llama2。从DDDD的效果来看,多种模态联合训练确实有用，但是它的用处主要在于：把文本抽象概念和物理实体形象的对应Grounding建立起来了，但是在大模型的世界知识和各种能力储备方面，经过大量视频强化过的DDDD甚至可能还比不过只用文本训练的GPT 4。本质上是大模型把从文本中学到的世界知识和逻辑能力，经过grounding绑定到实体外在形象后，在多模态场景下语言模型把丰富的世界知识迁移给了多模态模型.大量多模态训练数据新增的知识并不多.
C:可以用啊，我们试一试吧，推动产品来进步.
